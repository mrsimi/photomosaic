{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color matched image saved to f9c56401-f37b-483d-8b8a-086a19615f57_matched_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import uuid\n",
    "\n",
    "\n",
    "def color_match(image1, image2):\n",
    "    img1 = cv2.imread(image1)\n",
    "    img2 = cv2.imread(image2)\n",
    "    img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "    \n",
    "    img1_lab = cv2.cvtColor(img1, cv2.COLOR_BGR2LAB)\n",
    "    img2_lab = cv2.cvtColor(img2, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Calculate mean and standard deviation for each channel in LAB color space\n",
    "    img1_mean, img1_std = cv2.meanStdDev(img1_lab)\n",
    "    img2_mean, img2_std = cv2.meanStdDev(img2_lab)\n",
    "\n",
    "    # Perform color matching by adjusting mean and standard deviation\n",
    "    for i in range(3):  # Iterate over L, A, B channels\n",
    "        img1_lab[:,:,i] = img1_lab[:,:,i] - img1_mean[i]\n",
    "        img1_lab[:,:,i] = img1_lab[:,:,i] * (img2_std[i] / img1_std[i])\n",
    "        img1_lab[:,:,i] = img1_lab[:,:,i] + img2_mean[i]\n",
    "\n",
    "    # Convert back to BGR color space\n",
    "    matched_img = cv2.cvtColor(img1_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return matched_img\n",
    "\n",
    "# Example usage\n",
    "#image1- targeImage\n",
    "#image2 - palletImage\n",
    "target_image_path ='targetimage.jpeg'\n",
    "pallet_image_path = 'palletimage.jpeg'\n",
    "matched_image = color_match(target_image_path, pallet_image_path)\n",
    "\n",
    "# Display the matched image\n",
    "# cv2.imshow('Color Matched Image', matched_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "output_path = str(uuid.uuid4())+'_matched_image.jpg'\n",
    "cv2.imwrite(output_path, matched_image)\n",
    "print(f\"Color matched image saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('targetimage.jpeg')\n",
    "\n",
    "# Define the dimensions of each part\n",
    "num_rows = 3  # Number of rows for splitting\n",
    "num_cols = 3  # Number of columns for splitting\n",
    "height, width, _ = image.shape\n",
    "\n",
    "# Calculate the dimensions of each part\n",
    "part_height = height // num_rows\n",
    "part_width = width // num_cols\n",
    "\n",
    "# Initialize an empty list to store the parts\n",
    "image_parts = []\n",
    "\n",
    "# Iterate through rows and columns to split the image\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        # Calculate the starting and ending coordinates for each part\n",
    "        start_row = row * part_height\n",
    "        end_row = (row + 1) * part_height\n",
    "        start_col = col * part_width\n",
    "        end_col = (col + 1) * part_width\n",
    "        \n",
    "        # Extract the part from the image\n",
    "        part = image[start_row:end_row, start_col:end_col]\n",
    "        \n",
    "        # Append the part to the list\n",
    "        image_parts.append(part)\n",
    "        \n",
    "for i, part in enumerate(image_parts):\n",
    "    cv2.imwrite(f'part_{i+1}.jpg', part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load all the image parts\n",
    "image_parts = []\n",
    "for i in range(1, num_rows*num_cols + 1):  # Assuming num_rows and num_cols are defined\n",
    "    #part = cv2.imread(f'part_{i}.jpg')\n",
    "    part = color_match(f'part_{i}.jpg', 'palletimage.jpeg')\n",
    "    image_parts.append(part)\n",
    "\n",
    "# Determine the dimensions of the combined image\n",
    "combined_height = num_rows * part_height\n",
    "combined_width = num_cols * part_width\n",
    "\n",
    "# Create an empty canvas for the combined image\n",
    "combined_image = np.zeros((combined_height, combined_width, 3), dtype=np.uint8)\n",
    "\n",
    "# Combine the image parts into the final image\n",
    "for i, part in enumerate(image_parts):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    start_row = row * part_height\n",
    "    end_row = (row + 1) * part_height\n",
    "    start_col = col * part_width\n",
    "    end_col = (col + 1) * part_width\n",
    "    combined_image[start_row:end_row, start_col:end_col] = part\n",
    "\n",
    "# Optionally, save the combined image to a file\n",
    "cv2.imwrite('combined_image.jpg', combined_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color matched image saved to 2298fc3a-1a36-49a2-ae75-bd85a363fa7a_matched_image.jpg\n"
     ]
    }
   ],
   "source": [
    "mth_jpg = color_match('part_1.jpg', 'palletimage.jpeg')\n",
    "output_path = str(uuid.uuid4())+'_matched_image.jpg'\n",
    "cv2.imwrite(output_path, mth_jpg)\n",
    "print(f\"Color matched image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50,50,3) into shape (50,36,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m             best_tile \u001b[38;5;241m=\u001b[39m resized_tiles[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# Replace the region in the mosaic with the best matching tile\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m         \u001b[43mmosaic\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m best_tile\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Save the mosaic image\u001b[39;00m\n\u001b[1;32m     62\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmosaic.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, mosaic)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (50,50,3) into shape (50,36,3)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Load the large image\n",
    "large_image = cv2.imread('large_image.jpeg')\n",
    "\n",
    "# Directory containing tile images\n",
    "tile_dir = 'tiles_images/'\n",
    "tile_images = [os.path.join(tile_dir, img) for img in os.listdir(tile_dir)]\n",
    "\n",
    "# Resize tile images to a standard size (e.g., 50x50 pixels)\n",
    "tile_size = (50, 50)\n",
    "resized_tiles = [cv2.resize(cv2.imread(img), tile_size) for img in tile_images]\n",
    "\n",
    "# Flatten and reshape tile images for k-means clustering\n",
    "reshaped_tiles = [tile.reshape(-1, 3) for tile in resized_tiles]\n",
    "\n",
    "# Number of clusters for k-means (adjust as needed)\n",
    "num_clusters = 5\n",
    "\n",
    "# Perform k-means clustering on tile colors\n",
    "kmeans = MiniBatchKMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(np.vstack(reshaped_tiles))\n",
    "\n",
    "# Iterate over each region in the large image (e.g., using a sliding window)\n",
    "window_size = tile_size  # Adjust window size as needed\n",
    "mosaic = np.zeros_like(large_image)\n",
    "\n",
    "for y in range(0, large_image.shape[0], window_size[1]):\n",
    "    for x in range(0, large_image.shape[1], window_size[0]):\n",
    "        region = large_image[y:y + window_size[1], x:x + window_size[0]]\n",
    "        region_features = region.reshape(-1, 3)\n",
    "        \n",
    "        # Predict the cluster for the region using k-means\n",
    "        cluster = kmeans.predict(region_features)\n",
    "        \n",
    "        # Compute distances between region pixels and cluster centroids\n",
    "        distances = []\n",
    "        for pixel in region_features:\n",
    "            pixel_distances = np.linalg.norm(kmeans.cluster_centers_ - pixel, axis=1)\n",
    "            distances.append(np.min(pixel_distances))\n",
    "        \n",
    "        # Find the best matching tile image based on minimum distance\n",
    "        if distances:\n",
    "            best_tile_index = np.argmin(distances)\n",
    "            if 0 <= best_tile_index < len(resized_tiles):\n",
    "                best_tile = resized_tiles[best_tile_index]\n",
    "            else:\n",
    "                # Handle index out of range by selecting a default tile (e.g., first tile)\n",
    "                best_tile = resized_tiles[0]\n",
    "        else:\n",
    "            # Handle empty distances list by selecting a default tile (e.g., first tile)\n",
    "            best_tile = resized_tiles[0]\n",
    "        \n",
    "        # Replace the region in the mosaic with the best matching tile\n",
    "        mosaic[y:y + window_size[1], x:x + window_size[0]] = best_tile\n",
    "\n",
    "\n",
    "# Save the mosaic image\n",
    "cv2.imwrite('mosaic.jpg', mosaic)\n",
    "\n",
    "# # Display the mosaic image\n",
    "# cv2.imshow('Photo Mosaic', mosaic)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def split_images(target_image_path,dir, rows=3, columns=3):\n",
    "    image_parts = []\n",
    "    target = cv2.imread(target_image_path)\n",
    "    height, width, _ = target.shape\n",
    "    part_height = height // rows\n",
    "    part_width = width // columns\n",
    "    for row in range(rows):\n",
    "        for col in range(columns):\n",
    "            start_row = row * part_height\n",
    "            end_row = (row + 1) * part_height\n",
    "            start_col = col * part_width\n",
    "            end_col = (col + 1) * part_width\n",
    "\n",
    "            part = target[start_row:end_row, start_col:end_col]\n",
    "            image_parts.append(part)\n",
    "                \n",
    "        for i, part in enumerate(image_parts):\n",
    "            cv2.imwrite(f'{dir}/part_{i+1}.jpg', part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_images('large_image.jpeg', 'output', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Load the large image\n",
    "large_image = cv2.imread('large_image.jpeg')\n",
    "\n",
    "# Directory containing tile images\n",
    "tile_dir = 'tiles_images/'\n",
    "tile_images = [os.path.join(tile_dir, img) for img in os.listdir(tile_dir)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiles_images/pallet3.jpeg',\n",
       " 'tiles_images/pallet2.jpeg',\n",
       " 'tiles_images/pallet5.jpeg',\n",
       " 'tiles_images/pallet4.jpeg',\n",
       " 'tiles_images/pallet8.jpeg',\n",
       " 'tiles_images/pallet7.jpeg',\n",
       " 'tiles_images/pallet6.jpeg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize tile images to a standard size (e.g., 50x50 pixels)\n",
    "tile_size = (50, 50)\n",
    "resized_tiles = [cv2.resize(cv2.imread(img), tile_size) for img in tile_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MiniBatchKMeans(n_clusters=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MiniBatchKMeans</label><div class=\"sk-toggleable__content\"><pre>MiniBatchKMeans(n_clusters=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MiniBatchKMeans(n_clusters=5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten and reshape tile images for k-means clustering\n",
    "reshaped_tiles = [tile.reshape(-1, 3) for tile in resized_tiles]\n",
    "\n",
    "# Number of clusters for k-means (adjust as needed)\n",
    "num_clusters = 5\n",
    "\n",
    "# Perform k-means clustering on tile colors\n",
    "kmeans = MiniBatchKMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(np.vstack(reshaped_tiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_match_and_blend(region, tile):\n",
    "    # Resize the tile to match the size of the region\n",
    "    tile_resized = cv2.resize(tile, (region.shape[1], region.shape[0]))\n",
    "    \n",
    "    # Compute the average color of the region and resized tile\n",
    "    region_avg_color = np.mean(region, axis=(0, 1))\n",
    "    tile_avg_color = np.mean(tile_resized, axis=(0, 1))\n",
    "    \n",
    "    # Calculate the color difference between region and resized tile\n",
    "    color_diff = np.linalg.norm(region_avg_color - tile_avg_color)\n",
    "    \n",
    "    # Blend the region and resized tile based on color similarity\n",
    "    alpha = 1.0 - (color_diff / 255.0)  # Adjust alpha based on color difference\n",
    "    blended_region = cv2.addWeighted(region, alpha, tile_resized, 1.0 - alpha, 0)\n",
    "    \n",
    "    return blended_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each region in the large image (e.g., using a sliding window)\n",
    "window_size = tile_size  # Adjust window size as needed\n",
    "mosaic = np.zeros_like(large_image)\n",
    "\n",
    "for y in range(0, large_image.shape[0], window_size[1]):\n",
    "    for x in range(0, large_image.shape[1], window_size[0]):\n",
    "        region = large_image[y:y + window_size[1], x:x + window_size[0]]\n",
    "        #print(region.shape)\n",
    "        region_avg_color = np.mean(region, axis=(0, 1))  # Compute average color of the region\n",
    "        \n",
    "        # Find the best matching tile image based on average color difference\n",
    "        min_diff = float('inf')\n",
    "        best_tile = None\n",
    "        for tile in resized_tiles:\n",
    "            tile_avg_color = np.mean(tile, axis=(0, 1))\n",
    "            color_diff = np.linalg.norm(region_avg_color - tile_avg_color)\n",
    "            if color_diff < min_diff:\n",
    "                min_diff = color_diff\n",
    "                best_tile = tile\n",
    "        \n",
    "        # Replace the region in the mosaic with the best matching tile\n",
    "        blended_region = color_match_and_blend(region, best_tile)    \n",
    "        mosaic[y:y + window_size[1], x:x + window_size[0]] = cv2.resize(blended_region,(region.shape[1], region.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('mosaicr4lgk.jpg', mosaic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
